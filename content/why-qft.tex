\chapter{Principles of Quantum Field Theory}
\label{chap:intro}

\subsection{Historical Introduction}

The first three decades of the 20th century marked an unparalleled advance in fundamental physics. Sparked by the observation black body radiation --- specifically its sharp frequency cutoff which suppresses high-energy radiation --- Max Planck postulated in 1900 that the energy of light had to come in \emphi{quanta}. Inspired, Albert Einstein used this idea of light quanta to explain the photoelectric effect, and Niels Bohr and Ernest Rutherford generalized the idea of quanta by suggesting in 1913 that angular momentum was also quantized in order to explain atomic emission lines. With Louis de Broglie's proposal in 1924 that matter was also quantized, it became rare to find properties of nature that were \textit{not} quantized --- a statement made rigorous by the discovery of the \Schrodinger equation in 1926, and the foundation of non-relativistic quantum mechanics.

Independently, Maxwell's prediction and the following experimental confirmation that the speed of light be constant had initiated its own cascade of discoveries. In 1905, Einstein reshaped our definitions space and time by uniting them into one entity --- spacetime --- all in order to apply Maxwell's equations of electromagnetism on moving bodies. His new theory is now called special relativity. Ten years later, he unified special relativity with gravity to produce general relativity, which explained the slow precession of Mercury's orbit, and now explains much more exotic phenomena such as black holes and the history of the universe.

Though these two theories of relativity and quantum mechanics were each incredibly successful, they were completely in conflict. The famous \Schrodinger equation, though in agreement with experiment, contained one time derivative and two position derivatives:\footnote{This is the first time we have used natural units, wherein $\hbar = c = 1$.}
\begin{e}
  i\partial_t \psi = \parens{-\frac{1}{2m}\partial_x^2}\psi.
  \label{eqn:shrodinger}
\end{e}
We've set potential energy equal to zero assuming that the particle is in vacuum. According to special relativity, a Lorentz boost to a new reference frame with velocity $v$ must introduce the substitutions $\del_t \rightarrow \del_t + v \del_x$ and $\del_x \rightarrow \del_x + v \del_t$. But that would introduce additional space and time derivatives which no longer fit the form of (\ref{eqn:shrodinger}). Thus, the \Schrodinger equation is inconsistent with relativity.

A physicist in the 20s could have guessed at the qualitative behavior of a fully complete theory of physics; it should both inherit the core principles of both relativity and quantum mechanics, including the possibility of quantum tunneling and the famous statement of mass-energy equivalence --- $E=mc^2$. Together, these two imply that a particle could ``tunnel'' from energy $E$ and mass $m$ to a different energy $E'$ and mass $m'$, effectively switching to an entirely new particle type on its own. Thus, a relativistic quantum theory should predict particle creation, annihilation, and decay. It would take another forty years for the machinery to generate these predictions was worked it.

Aside from this theoretical problem with late 1920s-era physics, a few experimental anomalies had begun to appear. It was becoming increasingly apparent that electron spin, largely pioneered by Pauli, needed to be introduced to quantum mechanics. The spectrum of hydrogen, once the poster child of the quantization of angular momentum, was showing a small discrepancy with the theoretical prediction of $s$ orbital energy. Separately, Compton scattering experiments where high energy photons were scattered off electrons showed that light had important quantum mechanical properties which could not be understood with the \Schrodinger equation.

There were two examples of equations of motion already introduced in physics that were consistent with relativity: one was Maxwell's equations (in vacuum), written in terms of the vector potential $A^\mu$
\begin{e}
  \del_\mu \parens{\del^\mu A^\nu - \del^\nu A^\mu} = 0
  \label{eqn:maxwell}
\end{e}
and the other was the wave equation, also called the Klein-Gordon equation, written for a wavefunction $\phi$:
\begin{e}
  \del^\mu \del_\mu \phi^2 - m\phi^2 = 0.
  \label{eqn:klein-gordon}
\end{e}
Both of these equations are Lorentz invariant, though they are not good replacements for the \Schrodinger equation since they do not have the same non-relativistic limit. For the same reason, they also don't resolve the new experimental anomalies. Instead, Paul Dirac resolved them in 1928 with his famous Dirac Equation. Like the \Schrodinger equation, the Dirac equation is a one-derivative equation and consequentially reproduces the \Schrodinger equation in the non-relativisitic limit. In order to contract away the index of the single derivative $\del_\mu$, the Pauli matrices $\sigma_1$, $\sigma_2$, and $\sigma_3$ had to be combined with the identity into a four-vector $\sigma^\mu = (\mathds{1}, \sigma_1, \sigma_2, \sigma_3)$ which represents the spin operator.\footnote{(\ref{eqn:dirac}) only applies to massless particles, which is why $m$ is not present in the equation. It can be generalized to apply to massive particles such as electrons with some extra mathematical machinery, which is done in the main text.

The fact that spin and Lorentz invariance were resolved with the same blow in (\ref{eqn:dirac}) is no accident; spin, also known as intrinsic angular momentum, is only a valid particle property because it is conserved, and angular momentum is only conserved because physics is invariant under rotations. Lorentz invariance implies invariance under rotations, so any theory which is Lorentz invariance should also come with a complementary interpretation of angular momentum (or spin).}
\begin{e}
  i\parens{\del_\mu \sigma^\mu} \psi = 0.
  \label{eqn:dirac}
\end{e}
This was the first fundamental theory to describe particle spin. It also allowed the anomalous energy of the $s$ orbitals to be understood as a relativistic correction to the \Schrodinger equation, due to the electron's high velocity. The same theoretical tools addressed the Compton effect, with its relativistic electrons.

However, the Dirac equation had one glaring flaw. It predicted the existence of a new particle of equal mass to the electron but with opposite charge --- a particle which somehow had never been seen despite the recent surge of particle physics experiments. Ashamed of his prediction, Dirac postulated that the proton was this new electron-like particle, even though experiment had already shown that the proton was much more massive than the electron.

Four years later, it appeared Dirac should have stuck to his guns. The positron was discovered by Carl David Anderson and confirmed to have the same mass and opposite charge of the electron, though it decayed not long afterwards. However, the new particles didn't stop there. The neutron was discovered in the same year, and muon not long after in 1936. Together with these new particles was the ever-growing theory of nuclear decay, describing how protons, neutrons, and electrons conspired to turn into each other with fixed rates. No theory yet written allowed particles to change identity or split in such a way. 

Keeping pace with experiment, many physicists had embarked on several methods of promoting the Dirac equation and Maxwell's equations to a ``Quantum Field Theory,'' or QFT, which could handle the wavefunctions of several particles at once, allow them to interact and, crucially, to decay. Progress was slowed by the temperamental behavior of energy; the vacuum energy predicted by the \Schrodinger became infinite in a relativistic version, as did other quantities such as particle masses. Some physicists began to suggest abandoning the new QFT framework altogether. However, the occasional success kept many physicists on the QFT track. For example, a new anomaly of the Hydrogen $s$ orbital known as the Lamb shift was discovered in 1947 and explained by Hans Bethe using QFT, and a correction to the magnetic moment of the electron was derived in 1948 by Julian Schwinger and experimentally confirmed.

The theoretical troubles of QFT were redressed over the next decade through a number of procedures largely developed by Schwinger, Richard Feynman, and Shinichiro Tomonaga, for which they one the 1965 Nobel Prize in Physics. Their theory, named Quantum Electrodynamics (QED), explains all the phenomena of classical mechanics, non-relativistic quantum mechanics, and special relativity, as well as confirming all the new discoveries mentioned above. As of the 2000s, its predictions have been confirmed to as many as 12 decimal places in multiple experiments. The theory also addressed several philosophical questions, such as the origin of particle spin and the definitions of fermions and bosons. This book is largely devoted to understanding this theory and its consequences.

In the years since, many new particles have been discovered and the laws of QED have been generalized to the Standard Model, which is the most successful theory ever created. It is consistent with all scattering experiments performed in any collider, confirms the mass of nucleons such as the proton and neutron, and agrees with all measured particle properties except the neutrino masses. In the rest of this chapter, we summarize the physical principles underlying the standard model before introducing them in mathematical detail in the preceding chapters.

\subsection{The Principle of Least Action}

Despite the careening history of physics development, with its many different and inconsistent theories, every fundamental theory before QFT (classical mechanics, relativity, and quantum mechanics) had a principle of least action. It seems reasonable to pursue such a principle for QFT.

In classical mechanics, action $S$ is defined as the integral of some function $L$ with dimensions of energy, known as the Lagrangian, with respect to time. The integral is computed over the path $C$ taken by a particle:
\begin{e}
  S = \int_C dt \, L.
\end{e}
This definition is combined with the physical law that Nature choses the path $C$ such that the action is minimized. Thus, any small change to $C$ does not lower the action:
\begin{e}
  \delta S = 0.
  \label{eqn:least-action}
\end{e}
(\ref{eqn:least-action}) is known as the principle of least action.

The advantages of the action formulation are many. Firstly, it reduces all the properties of a physical theory to one variable: the Lagrangian. All a physicist need do to create a theory is write down a new form of $L$. Furthermore, a physicist is aided in the process of writing a new Lagrangian by the fact that all the symmetries of $S$ are symmetries of the theory in general. For example, we have observed that physics is invariant under translation --- that is, that experiments done in different locations yield the same results. Thus, $S$ cannot depend explicitly on position. Other examples of symmetry are invariance under orientation, and time translation. Relativity introduces Lorentz boosting as a symmetry, while QFT will introduce even more. All of these symmetries cut down so much on the number of forms $S$ can take that Lagrangians tend to be quite simple in practice. In classical mechanics, the Lagrangian is
\begin{e}
  L_\mathrm{Classical} = K - V
  \label{eqn:classical-lagrangian}
\end{e}
where $K$ and $V$ are kinetic and potential energy. All other terms are forbidden because they do not have the right units or the right symmetries. For example, a term proportional to momentum is not invariant under rotation.

In general relativity, the purpose of the Lagrangian is to dictate how the metric of spacetime $g_{\mu \nu}$. This requires us to change our thinking slightly, since the classical Lagrangian (\ref{eqn:classical-lagrangian}) was for a particle and $g_{\mu \nu}$ is not a particle. The solution is to think in terms of degrees of freedom. In classical mechanics, we minimized the action with respect to the position $x(t)$ and momentum $p(t)$ of a particle at each time. Now we change our degrees of freedom to $g_{\mu \nu}(x)$ --- the metric tensor at every point in space --- and employ the same procedure.

The time integral in the definition of action is not Lorentz-invariant, but the full spacetime volume element $d^4 x \sqrt{-g}$ is.\footnote{In the general relativistic Lagrangian density, $g$ is the determinant of the metric tensor $g_{\mu \nu}$, but we won't discuss it further because this book deals with flat spacetime.} Thus we must define the Lagrangian as
\begin{e}
  L = \int d^3 x\, \mathcal{L} \implies S = \int d^4 x\, \mathcal{L}(x).
\end{e}
where $\mathcal{L}(x)$ is called the \emphi{Lagrangian density}. Here we introduce a further principle, namely that general relativity is a \emphi{a local theory}. That is, the physics of one point in spacetime cannot be affected by a that of a distant point. Since $\mathcal{L}(x)$ encapsulates the physics at a point, it must only depend on $x$ and derivatives with respect to $x$. In practice, the way information is communicated across spacetime is by waves, much like the electromagnetic waves of Maxwell's equations, which is also a local theory.

Putting together the notion of a Lagrangian density with the requirement of Lorentz invariance and the principle that it must only depend on local variables, the general relativity Lagrangian density is
\begin{e}
  \mathcal{L}_\mathrm{GR} = \sqrt{-g} \parens{R - 2 \Lambda} + \mathcal{L}_\mathrm{Matter}.
\end{e}
Here, $R$ is the Ricci scalar (the simplest non-constant Lorentz-invariant scalar), and $\mathcal{L}_\mathrm{Matter}$ is the Lagrangian density of matter that happens to be present. $\Lambda$ is known as the cosmological constant which roughly represents the energy of the vacuum.

We often call $g_{\mu \nu}$ a field because it takes on a value at every point $x$ in spacetime. This then represents the first generalization of the principle of least action to a field --- that is, our first \emphi{field theory}. We could also treat the Klein-Gordon equation (\ref{eqn:klein-gordon}) or the Dirac equation (\ref{eqn:dirac}) as classical equations of motion for fields $\phi$ and $\psi$, and we would get Lagrangian densities
\begin{ec}
  \mathcal{L}_\mathrm{KG} = \phi(\del_\mu \del^\mu - m) \phi,
  \qquad \mathcal{L}_\mathrm{Dirac} = i\psi^\dagger (\sigma^\mu \del_\mu ) \psi\\
  \qquad \mathcal{L}_\mathrm{EM} = -\frac{1}{4}F_{\mu \nu} F^{\mu \nu}\\
  \label{eqn:all-actions}
\end{ec}
where $F^{\mu \nu}$ is the Faraday tensor $F^{\mu \nu} = \del^\mu A^\nu - \del^\nu A^\mu$.
However, these field theories are still classical because they do not produce quantized particles. Covering the principle of least action for a quantum theory is the next step.

\subsection{Quantum Principle of Least Action}

The success of quantum mechanics is largely due to the presence of the new constant $\hbar$, which has units of energy times time. $\hbar$ is necessary to quantize the energy of light, angular momentum, and to write the \Schrodinger equation, but $\hbar$ poses a problem for the principle of least action. Action has the same units as $\hbar$, so varying the path of a quantum particle could in principle change the action by any amount $\delta S = x\hbar$, where $x$ is a unitless number. Furthermore, a true quantum particle doesn't have a path. It has a wavefunction, and may exist anywhere within that wavefunction at any time.

Richard Feynman developed a simple solution to both these problems in the 40s. To compute the probability that a quantum particle could go from position $\ket{x(0)}$ at time $t=0$ to position $\ket{y(t)}$ at time $t$, one need only calculate

\begin{e}
  \braket{\bm x(t)\bm y(0)} = \sum_{\mathrm{paths}\ C} \expp{-\frac{i}{\hbar} \int_C dt\, L}.
  = \sum_{\mathrm{paths}\ C} e^{-i S / \hbar}.
  \label{eqn:quantum-least-action}
\end{e}

The sum over paths runs over all possible paths from $\bm x$ to $\bm y$, with each weighted by a phase of $e^{-i S / \hbar}$, where $S$ is computed over the path in question. This new action formulation acknowledges that quantum particles don't follow paths by equivalently stating that they follow \textit{every} path. It also resolves the question of units by dividing action by $\hbar$. We'll now go back to natural units where $\hbar = 1$.

Surprisingly, (\ref{eqn:quantum-least-action}) is almost equivalent to the classical principle of least action $\delta S = 0$. Consider a specific $C$, which corresponds to action $S_C$. This path contributes a term of $e^{iS_C}$ to $\braket{x(0)|y(t)}$, and all paths that differ only by a small action $\delta S$ contribute contribute $e^{iS_C}e^{i\delta S}$. When added, the positive $\delta S$ of some terms destructively interfere with the negative $\delta S$ of other terms, and the interference grows worse as larger and larger $\delta S$ are considered. However, if $C$ is the path that minimizes action, then there are no paths with negative $\delta S$, and there is no destructive interference. Thus, the paths that contribute the most to $\braket{x(0)|y(t)}$ are those that minimize or nearly minimize the action.\footnote{The rigorous version of this statement is known as the ``stationary phase approximation.''}

\subsubsection*{Quantum Field Theory Lagrangian}

Quantum field theory --- the relativistic version of quantum mechanics --- needs to share the field theory properties of relativity and the quantum properties of non-relativistic quantum mechanics. We'll start by borrowing the Lagrange density $\mathrm{L}$ of general relativity and the notion of minimizing action with respect to fields --- except this time we replace the field $g_{\mu \nu}$ with a wavefunction $\psi(x)$. The we interpret the notion of summing over paths as integrating over all possible values of $\psi(x)$. This integration, called \emphi{path integration} deserves a shorthand:

\begin{e}
  \prod_{x\ \in\ \mathrm{spacetime}}\int \psi(x) \equiv \int \mathcal{D}\psi.
\end{e}

The last step is to interpret the left hand side of (\ref{eqn:quantum-least-action}) in a Lorentz invariant way. We start with the vacuum $\ket 0$, which must be Lorentz invariant. If we define an operator $\hat \psi(x)$ which creates a particle at four-position $x$, then $\hat \psi(x)\ket{0}$ is a Lorentz-invariant, single-particle state. The non-relativistic quantum mechanics notation for such a state was $\ket{\bm x(t)}$x, where $x = (t, \bm x)$. Thus, the natural relativistic analog of the non-relativistic $\braket{\bm x(t) | \bm y(0)}$ in (\ref{eqn:quantum-least-action}) is $\braket{0 | \hat\psi(\bm x)\hat\psi(\bm y) | 0}$.

Given these insights, we extend (\ref{eqn:quantum-least-action}) to the relativistic case as follows

\begin{e}
  \braket{0|\hat\psi(x)\hat\psi(y)|0} \propto \int \mathcal{D}\psi\, \psi(x)\psi(y)\expp{-i \int d^4x\, \mathcal{L}}.
\end{e}
The proportionality is present because we have not yet normalized the wavefunction, but we can easily do this by dividing by $\braket{0|0}$:

\begin{e}
  \braket{0|\hat\psi(x)\hat\psi(y)|0} = \frac{\int \mathcal{D}\psi\, \psi(x)\psi(y)e^{-iS}}{\int \mathcal{D}\psi\,e^{-iS}},
\end{e}
where we've used the definition of action $S = \int d^4x\, \mathcal{L}$. Generalized to arbitrary expectation values,

\begin{e}
  \braket{0|\hat\psi(x_1)\cdots\hat\psi(x_n)|0} = \frac{\int \mathcal{D}\psi\, \psi(x_1)\cdots\psi(x_n)e^{-iS}}{{\int \mathcal{D}\psi\,e^{-iS}}}.
  \label{eqn:qft-least-action}
\end{e}

This law, due to Feynman, is the heart of QFT. It can be used to compute the outcome of scattering experiments, particle properties such as magnetic moments, and bound states like nuclei. The first two in particular can be done with the perturbative framework known as Feynman diagrams, which this book focuses on. Along with the quantitative predictions, (\ref{eqn:qft-least-action}) gives deep insight as to the nature of particles, since it can be used to derive the spin-statistics theorem which explains why spin-1/2 particles obey the Pauli exclusion principle.

\subsubsection*{Only a Few Lagrangians are Possible}

(\ref{eqn:qft-least-action}) also suppresses the influence of complex terms in the Lagrangian have on experiments, leaving only a few terms which we can observe. This can be seen as follows. Consider a scattering experiment, where two particles $\psi$ were collided with energy $E$. If $\mathcal{L}$ had a term like $\lambda \psi^4$, the constant $\lambda$ would need to have mass dimension $-2$ to satisfy unit analysis. Whenever this constant appeared in the scattering cross section, it would need to be accompanied with an energy to allow the units to work: $\lambda / E^{-2} = \lambda E^2$. Thus, it is measurable at high energies but not at low energies. ``High'' energies here should be compared to the mass energy of a particle, so that $E$ is high only for highly relativistic scenarios. Thus, these complex terms do not influence our low-energy environment.

There are only three terms which are Lorentz-invariant and low-dimension enough not to be suppressed. They are precisely the Lagrangians for Maxwell's equations, the Dirac equation, and the Klein-Gordon equation (\ref{eqn:all-actions}). Thus, the theory of quantum electrodynamics which simultaneously explains Maxwell's equations and the Dirac equation in the language of QFT, falls out naturally from (\ref{eqn:qft-least-action}). The only free parameters in the entire theory are the particle masses and value of the fine structure constant, $\alpha \approx 1/137$, which encapsulates the strength of the electric charge.

The fact that QFT narrows down the possible Lagrangian terms to only the ones Nature uses represents an incredible achievement of modern physics. We have boiled down incredibly complex phenomena to a mere handful of parameters using only the assumption of translational and Lorentz symmetry, locality, and the simple insights taken from the least action principles of other theories. The fantastic predictiveness of QFT is not lost when we extend beyond QED to the broader standard model; even taking all particles into account in the Lagrangian, nearly every term allowed by QFT exists in Nature's Lagrangian.

The next part of this book is dedicated to understanding the $n$-point correlation functions, which are the left hand side of (\ref{eqn:qft-least-action}). The second and third parts are dedicated to computing the right hand side depending on which Lagrangian is used. This book discusses perturbative methods, known as Feynman diagrams, for calculating this right hand side, though non-perturbative methods also exist under the name of Lattice QCD.

\jtd{Antiparticles and CPT symmetry. Also put in the daggers correctly for the QFT PLA}